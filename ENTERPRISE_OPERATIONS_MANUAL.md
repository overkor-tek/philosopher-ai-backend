# ================================================================
# OVERKORE ENTERPRISE OPERATIONS MANUAL
# ================================================================
# Production Deployment, Operations, Security, and Scaling Guide
# Version: 1.0
# Date: 2025-11-24
# Agent: C1 (Mechanic) - Strategic Documentation
# ================================================================

## ðŸŽ¯ PURPOSE

This manual provides comprehensive operational guidance for deploying, monitoring, maintaining, and scaling OVERKORE in production environments.

**Target Audience:** DevOps Engineers, SREs, System Administrators, Security Engineers

---

# ðŸ“‘ TABLE OF CONTENTS

## Part 1: Deployment
1. [Pre-Deployment Checklist](#pre-deployment-checklist)
2. [Docker Deployment](#docker-deployment)
3. [Kubernetes Deployment](#kubernetes-deployment)
4. [Cloud Provider Setup](#cloud-provider-setup)
5. [Environment Configuration](#environment-configuration)

## Part 2: Security Operations
6. [Security Posture](#security-posture)
7. [Secrets Management](#secrets-management)
8. [SSL/TLS Configuration](#ssltls-configuration)
9. [Rate Limiting](#rate-limiting)
10. [Security Monitoring](#security-monitoring)

## Part 3: Monitoring & Observability
11. [Health Checks](#health-checks)
12. [Metrics & Dashboards](#metrics--dashboards)
13. [Logging Strategy](#logging-strategy)
14. [Alerting Rules](#alerting-rules)
15. [Performance Monitoring](#performance-monitoring)

## Part 4: Incident Response
16. [Incident Response Protocol](#incident-response-protocol)
17. [Common Issues & Troubleshooting](#common-issues--troubleshooting)
18. [Rollback Procedures](#rollback-procedures)
19. [Data Recovery](#data-recovery)
20. [Post-Mortem Template](#post-mortem-template)

## Part 5: Scaling & Performance
21. [Horizontal Scaling](#horizontal-scaling)
22. [Vertical Scaling](#vertical-scaling)
23. [Database Optimization](#database-optimization)
24. [Caching Strategy](#caching-strategy)
25. [Load Balancing](#load-balancing)

## Part 6: Maintenance
26. [Backup Procedures](#backup-procedures)
27. [Update & Patch Management](#update--patch-management)
28. [Database Migrations](#database-migrations)
29. [Log Rotation](#log-rotation)
30. [Capacity Planning](#capacity-planning)

---

# PART 1: DEPLOYMENT

## Pre-Deployment Checklist

### âœ… Infrastructure Requirements
```bash
# Minimum Requirements (Single Node)
- CPU: 4 cores
- RAM: 8 GB
- Disk: 50 GB SSD
- Network: 1 Gbps

# Production Requirements (Kubernetes Cluster)
- Master Node: 4 CPU, 8 GB RAM
- Worker Nodes: 8 CPU, 16 GB RAM (minimum 3 nodes)
- Load Balancer: Cloud provider managed
- Database: 100 GB SSD, automated backups
```

### âœ… Software Prerequisites
```bash
# Required Software
- Docker 24.0+ (or Podman)
- Docker Compose 2.0+
- Kubernetes 1.28+ (for K8s deployment)
- kubectl configured
- Git 2.40+
- Node.js 18+ LTS
- Python 3.11+

# Verification Commands
docker --version
docker-compose --version
kubectl version --client
node --version
python3 --version
```

### âœ… Security Prerequisites
```bash
# Required Secrets (MUST be configured before deployment)
export JWT_SECRET="$(openssl rand -base64 32)"  # 32+ character strong secret
export DATABASE_ENCRYPTION_KEY="$(openssl rand -base64 32)"
export ADMIN_PASSWORD="$(openssl rand -base64 24)"

# Optional but Recommended
export SENTRY_DSN="https://your-sentry-dsn"
export DATADOG_API_KEY="your-datadog-key"
export SLACK_WEBHOOK_URL="https://hooks.slack.com/services/YOUR/WEBHOOK"
```

### âœ… Network Requirements
```bash
# Firewall Rules
Inbound:
  - TCP 443 (HTTPS) - Public
  - TCP 80 (HTTP â†’ HTTPS redirect) - Public
  - TCP 3001 (API) - Behind load balancer
  - TCP 6379 (Redis) - Internal only

Outbound:
  - TCP 443 (External APIs, package repos)
  - TCP 53 (DNS)
```

---

## Docker Deployment

### Quick Start (Development)
```bash
# 1. Clone repository
git clone [repository-url]
cd philosopher-ai-backend

# 2. Configure environment
cp .env.example .env
nano .env  # Set JWT_SECRET and other vars

# 3. Deploy
chmod +x deploy.sh
./deploy.sh development

# 4. Verify
curl http://localhost:3001/api/health
open http://localhost:3001/dashboard.html
```

### Production Deployment
```bash
# 1. Set production secrets
export JWT_SECRET="your-production-secret-32chars+"
export NODE_ENV="production"

# 2. Build production images
./deploy.sh production

# 3. Verify deployment
docker ps  # Should show overkore-api and redis
docker logs overkore-api  # Check for errors

# 4. Access dashboard
open http://your-domain/dashboard.html
```

### Docker Compose Services
```yaml
# docker-compose.yml overview
services:
  overkore-api:
    - Main API server (Node.js + Python)
    - Port: 3001 (external), 3000 (internal)
    - Health check: /api/health (30s interval)
    - Auto-restart: unless-stopped

  redis:
    - Rate limiting and caching
    - Port: 6379 (internal only)
    - Persistence: appendonly enabled
    - Memory limit: 512MB
```

### Docker Management Commands
```bash
# View logs
docker-compose logs -f overkore-api
docker-compose logs --tail=100 redis

# Restart services
docker-compose restart overkore-api
docker-compose restart redis

# Stop services
docker-compose down  # Stops but preserves data
docker-compose down -v  # DANGER: Deletes volumes

# Scale services (use K8s for production scaling)
docker-compose up -d --scale overkore-api=3
```

---

## Kubernetes Deployment

### Prerequisites
```bash
# 1. Kubernetes cluster (GKE, EKS, AKS, or self-hosted)
# 2. kubectl configured
# 3. Docker images pushed to registry

# Verify cluster access
kubectl cluster-info
kubectl get nodes
```

### Deploy to Kubernetes
```bash
# 1. Create namespace
kubectl create namespace overkore-production

# 2. Create secrets
kubectl create secret generic overkore-secrets \
  --from-literal=jwt-secret="$JWT_SECRET" \
  --from-literal=database-key="$DATABASE_ENCRYPTION_KEY" \
  --namespace=overkore-production

# 3. Deploy application
kubectl apply -f kubernetes.yml --namespace=overkore-production

# 4. Verify deployment
kubectl get pods -n overkore-production
kubectl get svc -n overkore-production
kubectl get hpa -n overkore-production  # Horizontal Pod Autoscaler

# 5. Check pod logs
kubectl logs -f deployment/overkore-api -n overkore-production
```

### Kubernetes Resources Deployed
```yaml
# kubernetes.yml creates:
1. Deployment (overkore-api)
   - Replicas: 3 (min), 10 (max)
   - Rolling update strategy
   - Resource limits: 500m CPU, 512Mi RAM
   - Resource requests: 250m CPU, 256Mi RAM

2. Service (LoadBalancer)
   - External access via cloud LB
   - Port 80 â†’ 3001

3. HorizontalPodAutoscaler
   - CPU target: 70%
   - Memory target: 80%
   - Min: 3 pods, Max: 10 pods

4. Redis Deployment
   - Single replica (consider Redis Cluster for HA)
   - Persistent volume
```

### Kubernetes Management
```bash
# Scale manually
kubectl scale deployment overkore-api --replicas=5 -n overkore-production

# Update deployment (rolling update)
kubectl set image deployment/overkore-api \
  overkore-api=your-registry/overkore:v2.0 \
  -n overkore-production

# Check rollout status
kubectl rollout status deployment/overkore-api -n overkore-production

# Rollback deployment
kubectl rollout undo deployment/overkore-api -n overkore-production

# View autoscaler status
kubectl get hpa -n overkore-production --watch
```

---

## Cloud Provider Setup

### AWS (EKS)
```bash
# 1. Create EKS cluster
eksctl create cluster \
  --name overkore-production \
  --region us-west-2 \
  --nodegroup-name standard-workers \
  --node-type t3.large \
  --nodes 3 \
  --nodes-min 3 \
  --nodes-max 10

# 2. Configure kubectl
aws eks update-kubeconfig --name overkore-production --region us-west-2

# 3. Deploy
kubectl apply -f kubernetes.yml
```

### Google Cloud (GKE)
```bash
# 1. Create GKE cluster
gcloud container clusters create overkore-production \
  --zone us-central1-a \
  --num-nodes 3 \
  --machine-type n1-standard-2 \
  --enable-autoscaling \
  --min-nodes 3 \
  --max-nodes 10

# 2. Get credentials
gcloud container clusters get-credentials overkore-production --zone us-central1-a

# 3. Deploy
kubectl apply -f kubernetes.yml
```

### Azure (AKS)
```bash
# 1. Create resource group
az group create --name overkore-rg --location eastus

# 2. Create AKS cluster
az aks create \
  --resource-group overkore-rg \
  --name overkore-production \
  --node-count 3 \
  --enable-addons monitoring \
  --generate-ssh-keys

# 3. Get credentials
az aks get-credentials --resource-group overkore-rg --name overkore-production

# 4. Deploy
kubectl apply -f kubernetes.yml
```

---

## Environment Configuration

### Critical Environment Variables
```bash
# Security (REQUIRED)
JWT_SECRET="32+ character random string"  # NEVER commit to git
DATABASE_ENCRYPTION_KEY="32+ character random string"
ADMIN_PASSWORD="Strong password for admin access"

# Application
NODE_ENV="production"  # production | development | staging
PORT=3001
API_VERSION="v1"

# Database
DATABASE_URL="sqlite:///consciousness.db"  # or PostgreSQL
DATABASE_POOL_SIZE=10
DATABASE_TIMEOUT=5000

# Redis (Rate Limiting)
REDIS_URL="redis://redis:6379"
REDIS_PASSWORD=""  # Set for production

# Logging
LOG_LEVEL="info"  # debug | info | warn | error
LOG_FORMAT="json"  # json | pretty
SENTRY_DSN="https://your-sentry-dsn"  # Error tracking

# Monitoring
ENABLE_METRICS=true
METRICS_PORT=9090
DATADOG_API_KEY=""  # Optional

# Rate Limiting
RATE_LIMIT_GLOBAL="200 per day"
RATE_LIMIT_HOURLY="50 per hour"
RATE_LIMIT_BURST="10 per minute"

# External APIs
ANTHROPIC_API_KEY=""  # For Claude integration
OPENAI_API_KEY=""  # For GPT integration
```

### Configuration File Locations
```bash
# Application Config
./config/production.js  # Node.js config
./config/settings.py    # Python config

# Security Config
./security_validation.py  # Input validation rules
./voice_interface_api.py  # Rate limiting rules

# Deployment Config
./Dockerfile
./docker-compose.yml
./kubernetes.yml
./deploy.sh
```

---

# PART 2: SECURITY OPERATIONS

## Security Posture

### Current Security Score: 93/100

**Achievements:**
- âœ… All 5 critical vulnerabilities fixed
- âœ… JWT secret validation (no hardcoded fallbacks)
- âœ… Input validation module (XSS, SQL injection, command injection)
- âœ… Rate limiting (Flask-Limiter)
- âœ… Path traversal protection
- âœ… 31 comprehensive security tests (100% pass)

**Remaining Work (to reach 100/100):**
- â³ Implement Web Application Firewall (WAF)
- â³ Add Content Security Policy (CSP) headers
- â³ Implement API key rotation
- â³ Add security headers (HSTS, X-Frame-Options)
- â³ Penetration testing (external audit)
- â³ Implement runtime application self-protection (RASP)
- â³ Add DDoS protection (Cloudflare/AWS Shield)

### Security Checklist (Weekly)
```bash
# 1. Run security tests
python3 test_security.py

# 2. Check for vulnerabilities
npm audit
pip check
docker scan your-image:latest

# 3. Review logs for suspicious activity
grep "401\|403\|429" /var/log/overkore/api.log | tail -100

# 4. Update dependencies
npm update
pip install --upgrade -r requirements.txt

# 5. Rotate secrets (monthly)
# Generate new JWT_SECRET and deploy
```

---

## Secrets Management

### Never Commit Secrets to Git
```bash
# Check .gitignore includes:
.env
.env.local
.env.production
*.key
*.pem
secrets/
```

### Production Secrets Management

#### Option 1: Kubernetes Secrets
```bash
# Create secret
kubectl create secret generic overkore-secrets \
  --from-literal=jwt-secret="$JWT_SECRET" \
  --from-literal=db-password="$DB_PASSWORD" \
  --namespace=overkore-production

# Reference in deployment
env:
  - name: JWT_SECRET
    valueFrom:
      secretKeyRef:
        name: overkore-secrets
        key: jwt-secret
```

#### Option 2: AWS Secrets Manager
```bash
# Store secret
aws secretsmanager create-secret \
  --name overkore/jwt-secret \
  --secret-string "$JWT_SECRET"

# Retrieve in application
aws secretsmanager get-secret-value \
  --secret-id overkore/jwt-secret \
  --query SecretString \
  --output text
```

#### Option 3: HashiCorp Vault
```bash
# Store secret
vault kv put secret/overkore/jwt JWT_SECRET="$JWT_SECRET"

# Retrieve
vault kv get -field=JWT_SECRET secret/overkore/jwt
```

### Secret Rotation Procedure
```bash
# 1. Generate new secret
NEW_JWT_SECRET=$(openssl rand -base64 32)

# 2. Update secret in secrets manager
kubectl create secret generic overkore-secrets-new \
  --from-literal=jwt-secret="$NEW_JWT_SECRET" \
  --namespace=overkore-production

# 3. Update deployment to use new secret
kubectl patch deployment overkore-api \
  -p '{"spec":{"template":{"spec":{"containers":[{"name":"overkore-api","env":[{"name":"JWT_SECRET","valueFrom":{"secretKeyRef":{"name":"overkore-secrets-new"}}}]}]}}}}' \
  -n overkore-production

# 4. Rolling restart
kubectl rollout restart deployment/overkore-api -n overkore-production

# 5. Verify no errors
kubectl logs -f deployment/overkore-api -n overkore-production

# 6. Delete old secret (after validation period)
kubectl delete secret overkore-secrets -n overkore-production
```

---

## SSL/TLS Configuration

### Let's Encrypt (Free SSL)
```bash
# 1. Install certbot
apt-get install certbot python3-certbot-nginx

# 2. Obtain certificate
certbot --nginx -d yourdomain.com -d www.yourdomain.com

# 3. Auto-renewal
echo "0 0,12 * * * root certbot renew --quiet" >> /etc/crontab
```

### Kubernetes Ingress with TLS
```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: overkore-ingress
  annotations:
    cert-manager.io/cluster-issuer: letsencrypt-prod
spec:
  tls:
  - hosts:
    - yourdomain.com
    secretName: overkore-tls
  rules:
  - host: yourdomain.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: overkore-api
            port:
              number: 3001
```

---

## Rate Limiting

### Current Rate Limits
```python
# Global limits (voice_interface_api.py)
default_limits=["200 per day", "50 per hour"]

# Endpoint-specific
/api/v1/query:       10 per minute (sensitive)
/api/v1/search:      30 per minute (moderate)
/api/v1/health:      15 per minute (monitoring)
```

### Adjust Rate Limits
```python
# Edit voice_interface_api.py
limiter = Limiter(
    app=app,
    key_func=get_remote_address,
    default_limits=["500 per day", "100 per hour"],  # Adjust here
    storage_uri="redis://redis:6379",  # Use Redis for distributed rate limiting
)

# Endpoint-specific
@app.route('/api/v1/query', methods=['POST'])
@limiter.limit("20 per minute")  # Increase from 10 to 20
def process_query():
    pass
```

### Rate Limit Monitoring
```bash
# Check Redis rate limit keys
redis-cli --scan --pattern "*rate-limit*"

# View current counts
redis-cli GET rate-limit:127.0.0.1:/api/v1/query

# Clear rate limit for IP (emergency)
redis-cli DEL rate-limit:1.2.3.4:/api/v1/query
```

---

## Security Monitoring

### Security Test Suite
```bash
# Run comprehensive security tests
python3 test_security.py

# Expected output:
# 31/31 tests passed
# - XSS Protection: 6/6
# - SQL Injection: 5/5
# - Command Injection: 5/5
# - Path Traversal: 5/5
# - Input Validation: 6/6
# - API Validation: 3/3
# - Rate Limiting: 1/1
```

### Log Analysis for Security Events
```bash
# Failed authentication attempts
grep "401 Unauthorized" /var/log/overkore/api.log | wc -l

# Rate limit hits
grep "429 Too Many Requests" /var/log/overkore/api.log

# Suspicious input patterns
grep -E "(script>|SELECT.*FROM|\.\.\/)" /var/log/overkore/api.log

# IP addresses with most 401s (potential attackers)
grep "401" /var/log/overkore/api.log | awk '{print $1}' | sort | uniq -c | sort -rn | head -10
```

### Security Alerts
```bash
# Configure Slack webhooks for security events
# Edit security_validation.py to add alerting

def alert_security_incident(incident_type, details):
    webhook_url = os.getenv('SLACK_WEBHOOK_URL')
    payload = {
        "text": f"ðŸš¨ Security Alert: {incident_type}",
        "attachments": [{
            "color": "danger",
            "fields": [
                {"title": "Details", "value": details, "short": False}
            ]
        }]
    }
    requests.post(webhook_url, json=payload)
```

---

# PART 3: MONITORING & OBSERVABILITY

## Health Checks

### Application Health Endpoint
```bash
# Check health status
curl http://localhost:3001/api/health

# Expected response:
{
  "status": "healthy",
  "uptime": 86400,
  "memory": {
    "rss": 123456789,
    "heapTotal": 45678901,
    "heapUsed": 23456789
  },
  "services": {
    "database": "connected",
    "redis": "connected"
  }
}
```

### Kubernetes Health Probes
```yaml
# Already configured in kubernetes.yml
livenessProbe:
  httpGet:
    path: /api/health
    port: 3001
  initialDelaySeconds: 30
  periodSeconds: 10
  failureThreshold: 3

readinessProbe:
  httpGet:
    path: /api/health
    port: 3001
  initialDelaySeconds: 10
  periodSeconds: 5
  failureThreshold: 2
```

### Health Check Monitoring
```bash
# Continuous monitoring script
while true; do
  response=$(curl -s http://localhost:3001/api/health)
  status=$(echo $response | jq -r '.status')
  if [ "$status" != "healthy" ]; then
    echo "[ALERT] Service unhealthy: $response"
    # Send alert
  fi
  sleep 30
done
```

---

## Metrics & Dashboards

### Dashboard Access
```bash
# Open real-time dashboard
open http://your-domain/dashboard.html

# Dashboard shows:
- System health (CPU, memory, disk)
- Active requests
- Response times
- Error rates
- Request rate
- Database connections
- Cache hit rate
```

### Prometheus Metrics (Optional)
```javascript
// Add to server-simple.js
const promClient = require('prom-client');
const register = new promClient.Registry();

// Metrics
const httpRequestDuration = new promClient.Histogram({
  name: 'http_request_duration_seconds',
  help: 'Duration of HTTP requests in seconds',
  labelNames: ['method', 'route', 'status_code']
});

// Expose /metrics endpoint
app.get('/metrics', async (req, res) => {
  res.set('Content-Type', register.contentType);
  res.end(await register.metrics());
});
```

### Grafana Dashboard (Optional)
```bash
# Install Grafana
docker run -d \
  --name=grafana \
  -p 3000:3000 \
  grafana/grafana

# Add Prometheus data source
# Import OVERKORE dashboard JSON

# Key metrics to track:
- Request rate (req/s)
- Response time (p50, p95, p99)
- Error rate (%)
- Active connections
- Memory usage
- CPU usage
```

---

## Logging Strategy

### Log Levels
```bash
# NODE_ENV=development: DEBUG level (verbose)
# NODE_ENV=production: INFO level (structured)

export LOG_LEVEL=info  # debug | info | warn | error
export LOG_FORMAT=json  # json | pretty
```

### Log Locations
```bash
# Docker deployment
docker logs overkore-api

# Kubernetes deployment
kubectl logs -f deployment/overkore-api -n overkore-production

# System logs (if using systemd)
journalctl -u overkore-api -f

# File-based logs (if configured)
/var/log/overkore/api.log
/var/log/overkore/error.log
/var/log/overkore/security.log
```

### Structured Logging
```javascript
// All logs are JSON formatted in production
{
  "timestamp": "2025-11-24T19:30:00.000Z",
  "level": "info",
  "message": "Request processed",
  "method": "POST",
  "path": "/api/v1/query",
  "status": 200,
  "duration": 123,
  "ip": "1.2.3.4",
  "userId": "user-123"
}
```

### Log Aggregation (Optional)
```bash
# ELK Stack (Elasticsearch, Logstash, Kibana)
# Or use cloud services:
- AWS CloudWatch Logs
- Google Cloud Logging
- Azure Monitor
- Datadog
- Splunk
```

---

## Alerting Rules

### Critical Alerts (Page on-call)
```yaml
# Error rate > 5%
# Response time p95 > 2 seconds
# Pod crash loop
# Disk usage > 90%
# Database connection failure
# Redis connection failure
```

### Warning Alerts (Slack notification)
```yaml
# Error rate > 1%
# Response time p95 > 1 second
# CPU usage > 80%
# Memory usage > 80%
# Request rate spike (2x normal)
```

### Alert Configuration (Prometheus AlertManager)
```yaml
groups:
- name: overkore-alerts
  rules:
  - alert: HighErrorRate
    expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.05
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "High error rate detected"
      description: "Error rate is {{ $value }} (threshold: 5%)"
```

---

## Performance Monitoring

### Key Performance Indicators (KPIs)
```bash
# Target Metrics
- Response time p50: < 100ms
- Response time p95: < 500ms
- Response time p99: < 1000ms
- Error rate: < 0.1%
- Uptime: > 99.9%
- Request capacity: 10,000+ req/s
```

### Performance Testing
```bash
# Load test with Apache Bench
ab -n 10000 -c 100 http://localhost:3001/api/health

# Load test with wrk
wrk -t4 -c100 -d30s http://localhost:3001/api/health

# Stress test
wrk -t8 -c1000 -d60s --latency http://localhost:3001/api/v1/query

# Expected results (on 4-core, 8GB machine):
# Requests/sec: 5,000 - 10,000+
# Latency p50: 50-100ms
# Latency p99: < 1000ms
```

### Profiling
```bash
# Node.js profiling
node --prof server-simple.js
node --prof-process isolate-*.log > profile.txt

# Python profiling
python -m cProfile -o profile.stats voice_interface_v3_production.py
python -m pstats profile.stats
```

---

# PART 4: INCIDENT RESPONSE

## Incident Response Protocol

### Severity Levels

**SEV-1 (Critical):**
- Service completely down
- Data loss or corruption
- Security breach
- Response: Immediate, page on-call

**SEV-2 (High):**
- Partial service degradation
- Performance < 50% normal
- Non-critical feature broken
- Response: Within 1 hour

**SEV-3 (Medium):**
- Minor bugs affecting some users
- Performance degradation < 20%
- Response: Within 4 hours

**SEV-4 (Low):**
- Cosmetic issues
- Documentation errors
- Response: Next business day

### Incident Response Steps

#### 1. Detection
```bash
# Automated alerts (Prometheus, Datadog, etc.)
# User reports
# Monitoring dashboard anomalies
```

#### 2. Acknowledge
```bash
# Acknowledge alert
# Create incident ticket
# Notify team via Slack/PagerDuty
```

#### 3. Investigate
```bash
# Check logs
kubectl logs -f deployment/overkore-api -n overkore-production --tail=200

# Check pod status
kubectl get pods -n overkore-production

# Check resource usage
kubectl top pods -n overkore-production

# Check recent deployments
kubectl rollout history deployment/overkore-api -n overkore-production
```

#### 4. Mitigate
```bash
# Rollback if recent deployment caused issue
kubectl rollout undo deployment/overkore-api -n overkore-production

# Scale up if capacity issue
kubectl scale deployment overkore-api --replicas=10 -n overkore-production

# Restart if memory leak
kubectl rollout restart deployment/overkore-api -n overkore-production
```

#### 5. Communicate
```bash
# Update status page
# Notify stakeholders
# Post updates every 30 minutes during SEV-1
```

#### 6. Resolve
```bash
# Verify service restored
# Run smoke tests
# Monitor for stability (30 minutes)
```

#### 7. Post-Mortem
```bash
# Write post-mortem (see template below)
# Action items for prevention
# Share learnings with team
```

---

## Common Issues & Troubleshooting

### Issue: Service Not Starting

**Symptoms:**
```bash
kubectl get pods  # Shows CrashLoopBackOff
```

**Diagnosis:**
```bash
# Check pod logs
kubectl logs pod-name -n overkore-production

# Check events
kubectl describe pod pod-name -n overkore-production
```

**Common Causes & Fixes:**
```bash
# 1. Missing JWT_SECRET
# Fix: Ensure secret exists
kubectl get secrets -n overkore-production

# 2. Database connection failure
# Fix: Check database URL, credentials

# 3. Port already in use
# Fix: Change PORT environment variable

# 4. Insufficient resources
# Fix: Increase resource limits in kubernetes.yml
```

---

### Issue: High Response Times

**Symptoms:**
```bash
# Dashboard shows p95 latency > 2s
```

**Diagnosis:**
```bash
# Check CPU/memory usage
kubectl top pods -n overkore-production

# Check database performance
# Check for slow queries

# Profile application
node --prof server-simple.js
```

**Fixes:**
```bash
# 1. Scale up
kubectl scale deployment overkore-api --replicas=5 -n overkore-production

# 2. Add caching
# Implement Redis caching for expensive queries

# 3. Database optimization
# Add indexes, optimize queries

# 4. CDN for static assets
# Use Cloudflare or similar
```

---

### Issue: High Error Rate

**Symptoms:**
```bash
# Dashboard shows error rate > 5%
```

**Diagnosis:**
```bash
# Check error logs
kubectl logs deployment/overkore-api -n overkore-production | grep ERROR

# Check specific error types
grep "500 Internal Server Error" logs
```

**Fixes:**
```bash
# 1. Recent deployment issue
# Rollback
kubectl rollout undo deployment/overkore-api -n overkore-production

# 2. External API failure
# Implement circuit breaker, retries

# 3. Database connection pool exhausted
# Increase pool size in config
```

---

### Issue: Rate Limiting False Positives

**Symptoms:**
```bash
# Legitimate users getting 429 errors
```

**Diagnosis:**
```bash
# Check rate limit logs
grep "429" /var/log/overkore/api.log

# Check Redis rate limit keys
redis-cli --scan --pattern "*rate-limit*"
```

**Fixes:**
```bash
# 1. Increase rate limits
# Edit voice_interface_api.py, increase limits

# 2. Whitelist IP addresses
# Add IP whitelist in rate limiting config

# 3. Clear rate limit for specific IP
redis-cli DEL rate-limit:1.2.3.4:/api/v1/query
```

---

## Rollback Procedures

### Kubernetes Rollback
```bash
# View rollout history
kubectl rollout history deployment/overkore-api -n overkore-production

# Rollback to previous version
kubectl rollout undo deployment/overkore-api -n overkore-production

# Rollback to specific revision
kubectl rollout undo deployment/overkore-api --to-revision=3 -n overkore-production

# Verify rollback
kubectl rollout status deployment/overkore-api -n overkore-production
```

### Docker Rollback
```bash
# Stop current version
docker-compose down

# Pull previous version
docker pull your-registry/overkore:v1.9

# Update docker-compose.yml to use v1.9

# Start previous version
docker-compose up -d

# Verify
docker ps
curl http://localhost:3001/api/health
```

### Database Rollback
```bash
# Restore from backup (see Data Recovery section)
python3 backup_system.py restore --date=2025-11-23

# Verify data integrity
python3 system_dashboard.py --check-database
```

---

## Data Recovery

### Backup Strategy
```bash
# Automated daily backups (configured in backup_system.py)
- Database: Daily at 02:00 UTC
- Configuration: Daily at 03:00 UTC
- Logs: Weekly rotation, 30-day retention

# Backup locations
/backups/consciousness_db_YYYYMMDD.sql
/backups/config_YYYYMMDD.tar.gz
/backups/logs_YYYYMMDD.tar.gz
```

### Restore from Backup
```bash
# List available backups
ls -lh /backups/

# Restore database
python3 backup_system.py restore --date=2025-11-23

# Or manual restore
sqlite3 consciousness.db < /backups/consciousness_db_20251123.sql

# Verify restoration
python3 system_dashboard.py --verify-database
```

### Point-in-Time Recovery (if using PostgreSQL)
```bash
# PostgreSQL WAL-based recovery
# Configure continuous archiving
# Restore to specific timestamp

pg_basebackup -D /var/lib/postgresql/backup
# Restore process depends on PostgreSQL config
```

---

## Post-Mortem Template

```markdown
# Post-Mortem: [Incident Title]

**Date:** 2025-11-24
**Severity:** SEV-1 / SEV-2 / SEV-3
**Duration:** X hours Y minutes
**Incident Leader:** [Name]

## Summary
[Brief description of the incident]

## Impact
- **Users Affected:** X users (Y%)
- **Revenue Impact:** $Z
- **Reputation Impact:** [Description]

## Timeline (UTC)
- 10:00 - Incident detected
- 10:05 - Team notified
- 10:15 - Root cause identified
- 10:30 - Mitigation applied
- 11:00 - Service restored
- 11:30 - Monitoring confirmed stability

## Root Cause
[Detailed explanation of what caused the incident]

## What Went Well
- Fast detection (5 minutes)
- Clear communication
- Effective rollback

## What Could Be Improved
- Earlier detection (add new alert)
- Faster rollback (automate)
- Better documentation

## Action Items
1. [ ] Add monitoring for [specific metric] (Owner: X, Due: DATE)
2. [ ] Automate rollback for [scenario] (Owner: Y, Due: DATE)
3. [ ] Update runbook with [new procedure] (Owner: Z, Due: DATE)
4. [ ] Conduct training on [topic] (Owner: A, Due: DATE)

## Lessons Learned
[Key takeaways for the team]

**Next Steps:**
- Review this post-mortem in team meeting
- Track action items to completion
- Share learnings organization-wide
```

---

# PART 5: SCALING & PERFORMANCE

## Horizontal Scaling

### Kubernetes Auto-Scaling (Already Configured)
```yaml
# HorizontalPodAutoscaler in kubernetes.yml
- Min replicas: 3
- Max replicas: 10
- CPU target: 70%
- Memory target: 80%

# Auto-scaling behavior:
- Scale up when CPU > 70% for 30 seconds
- Scale down when CPU < 50% for 5 minutes
```

### Manual Scaling
```bash
# Scale to specific replica count
kubectl scale deployment overkore-api --replicas=7 -n overkore-production

# Check current replicas
kubectl get deployment overkore-api -n overkore-production

# Watch auto-scaling in action
kubectl get hpa -n overkore-production --watch
```

### When to Scale
```bash
# Scale up when:
- Response time p95 > 1 second
- CPU usage > 80% sustained
- Error rate increases
- Traffic spike expected (marketing campaign)

# Scale down when:
- CPU usage < 30% sustained
- Off-peak hours
- Cost optimization
```

---

## Vertical Scaling

### Increase Resource Limits
```yaml
# Edit kubernetes.yml
resources:
  limits:
    cpu: 1000m        # Increase from 500m
    memory: 1Gi       # Increase from 512Mi
  requests:
    cpu: 500m         # Increase from 250m
    memory: 512Mi     # Increase from 256Mi
```

### Apply Changes
```bash
kubectl apply -f kubernetes.yml -n overkore-production

# Rolling update will apply new resource limits
kubectl rollout status deployment/overkore-api -n overkore-production
```

---

## Database Optimization

### SQLite Optimization (Current)
```sql
-- Add indexes for common queries
CREATE INDEX idx_consciousness_timestamp ON consciousness_data(timestamp);
CREATE INDEX idx_consciousness_user ON consciousness_data(user_id);

-- Enable WAL mode for better concurrency
PRAGMA journal_mode=WAL;

-- Optimize cache
PRAGMA cache_size=10000;
```

### Migrate to PostgreSQL (for Scale)
```bash
# When SQLite becomes bottleneck (>10K users)
# Migrate to PostgreSQL for:
- Better concurrency
- Full-text search
- Replication
- Partitioning

# Migration process:
1. Set up PostgreSQL database
2. Export SQLite data: sqlite3 consciousness.db .dump > dump.sql
3. Convert to PostgreSQL format
4. Import to PostgreSQL
5. Update DATABASE_URL
6. Test thoroughly
7. Switch traffic
```

---

## Caching Strategy

### Redis Caching (Already Available)
```python
# Add caching to voice_interface_v3_production.py
import redis

redis_client = redis.Redis(host='redis', port=6379, db=0)

def get_response(query):
    # Check cache first
    cached = redis_client.get(f"response:{query}")
    if cached:
        return cached.decode('utf-8')

    # Generate response
    response = generate_response(query)

    # Cache for 1 hour
    redis_client.setex(f"response:{query}", 3600, response)

    return response
```

### Cache Invalidation
```python
# Invalidate specific keys
redis_client.delete(f"response:{query}")

# Invalidate pattern
for key in redis_client.scan_iter("response:*"):
    redis_client.delete(key)
```

---

## Load Balancing

### Kubernetes Service (Built-in)
```yaml
# Service in kubernetes.yml already provides load balancing
# Round-robin across all healthy pods
# Automatic health checks
# Session affinity optional
```

### External Load Balancer
```bash
# Cloud provider load balancers:
- AWS: Application Load Balancer (ALB) or Network Load Balancer (NLB)
- GCP: Cloud Load Balancing
- Azure: Azure Load Balancer

# Benefits:
- SSL termination
- DDoS protection
- CDN integration
- WAF integration
```

---

# PART 6: MAINTENANCE

## Backup Procedures

### Automated Backups (Already Configured)
```bash
# backup_system.py runs daily backups

# Backup schedule:
- 02:00 UTC - Database backup
- 03:00 UTC - Configuration backup
- 04:00 UTC - Log archive

# Retention policy:
- Daily backups: 7 days
- Weekly backups: 4 weeks
- Monthly backups: 12 months
```

### Manual Backup
```bash
# Database backup
python3 backup_system.py backup --type=database

# Configuration backup
python3 backup_system.py backup --type=config

# Full backup
python3 backup_system.py backup --type=full

# List backups
ls -lh /backups/
```

### Offsite Backup
```bash
# Sync to cloud storage (recommended)
# AWS S3
aws s3 sync /backups/ s3://overkore-backups/

# Google Cloud Storage
gsutil -m rsync -r /backups/ gs://overkore-backups/

# Azure Blob Storage
az storage blob upload-batch -d overkore-backups -s /backups/
```

---

## Update & Patch Management

### Security Updates (Monthly)
```bash
# 1. Update dependencies
npm update
pip install --upgrade -r requirements.txt

# 2. Check for vulnerabilities
npm audit
pip check

# 3. Test updates in staging
./deploy.sh staging

# 4. Deploy to production
./deploy.sh production
```

### Application Updates
```bash
# 1. Build new version
docker build -t your-registry/overkore:v2.1 .

# 2. Push to registry
docker push your-registry/overkore:v2.1

# 3. Update Kubernetes deployment
kubectl set image deployment/overkore-api \
  overkore-api=your-registry/overkore:v2.1 \
  -n overkore-production

# 4. Monitor rollout
kubectl rollout status deployment/overkore-api -n overkore-production

# 5. Verify
curl http://your-domain/api/health
```

---

## Database Migrations

### Migration Runner (Already Available)
```bash
# Run migrations
python3 migration_runner.py up

# Rollback migration
python3 migration_runner.py down

# Check migration status
python3 migration_runner.py status
```

### Create New Migration
```python
# migrations/003_add_user_preferences.py
def up():
    """Apply migration"""
    conn = sqlite3.connect('consciousness.db')
    cursor = conn.cursor()
    cursor.execute("""
        CREATE TABLE user_preferences (
            user_id TEXT PRIMARY KEY,
            preferences TEXT
        )
    """)
    conn.commit()
    conn.close()

def down():
    """Rollback migration"""
    conn = sqlite3.connect('consciousness.db')
    cursor = conn.cursor()
    cursor.execute("DROP TABLE user_preferences")
    conn.commit()
    conn.close()
```

---

## Log Rotation

### Docker Logs
```bash
# Configure in docker-compose.yml
services:
  overkore-api:
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
```

### System Logs
```bash
# Configure logrotate
cat > /etc/logrotate.d/overkore <<EOF
/var/log/overkore/*.log {
    daily
    rotate 30
    compress
    delaycompress
    notifempty
    create 0644 overkore overkore
    postrotate
        systemctl reload overkore-api
    endscript
}
EOF
```

---

## Capacity Planning

### Resource Usage Trends
```bash
# Track resource usage over time
# Use Prometheus/Grafana or cloud provider metrics

# Key metrics to track:
- CPU usage (average, peak)
- Memory usage (average, peak)
- Disk usage (growth rate)
- Request rate (average, peak)
- Database size (growth rate)
```

### Growth Projections
```bash
# Example capacity plan:

# Current (Month 1):
- Users: 1,000
- Requests: 10,000 req/day
- Database: 1 GB
- Resources: 3 pods, 4 CPU, 8 GB RAM

# Month 3:
- Users: 5,000 (5x growth)
- Requests: 50,000 req/day
- Database: 5 GB
- Resources: 5 pods, 4 CPU, 8 GB RAM

# Month 6:
- Users: 20,000 (20x growth)
- Requests: 200,000 req/day
- Database: 20 GB
- Resources: 10 pods, 8 CPU, 16 GB RAM
- Consider: Database sharding, CDN

# Month 12:
- Users: 100,000 (100x growth)
- Requests: 1M req/day
- Database: 100 GB
- Resources: Multi-region deployment
- Consider: Microservices, message queue
```

### Scaling Decision Matrix
```bash
# When to scale infrastructure:
- CPU usage > 70% sustained: Scale up
- Memory usage > 80% sustained: Scale up
- Disk usage > 80%: Increase storage
- Request rate 2x normal: Scale out
- Database size > 50 GB: Consider sharding
- Response time p95 > 1s: Scale up or optimize
```

---

# ðŸ“š APPENDICES

## Appendix A: Quick Reference Commands

### Deployment
```bash
# Deploy development
./deploy.sh development

# Deploy production
./deploy.sh production

# Deploy to Kubernetes
kubectl apply -f kubernetes.yml -n overkore-production
```

### Monitoring
```bash
# Check health
curl http://localhost:3001/api/health

# View logs
kubectl logs -f deployment/overkore-api -n overkore-production

# Check pod status
kubectl get pods -n overkore-production
```

### Troubleshooting
```bash
# Restart pods
kubectl rollout restart deployment/overkore-api -n overkore-production

# Rollback deployment
kubectl rollout undo deployment/overkore-api -n overkore-production

# Scale pods
kubectl scale deployment overkore-api --replicas=5 -n overkore-production
```

---

## Appendix B: Security Hardening Checklist

- [x] JWT secret validation (no hardcoded fallbacks)
- [x] Input validation (XSS, SQL injection, command injection)
- [x] Rate limiting (Flask-Limiter)
- [x] Path traversal protection
- [x] Security test suite (31 tests)
- [ ] Web Application Firewall (WAF)
- [ ] Content Security Policy (CSP) headers
- [ ] HSTS headers
- [ ] X-Frame-Options headers
- [ ] API key rotation
- [ ] DDoS protection
- [ ] Penetration testing
- [ ] Security audit (external)

---

## Appendix C: Performance Optimization Checklist

- [x] Docker multi-stage builds
- [x] Resource limits configured
- [x] Auto-scaling configured
- [x] Redis available for caching
- [ ] Implement Redis caching for queries
- [ ] Database indexes optimized
- [ ] CDN for static assets
- [ ] Gzip compression enabled
- [ ] Database connection pooling
- [ ] Load testing completed
- [ ] Performance profiling completed

---

## Appendix D: Contact Information

### On-Call Rotation
```bash
# Primary: [Name], [Phone], [Email]
# Secondary: [Name], [Phone], [Email]
# Escalation: [Name], [Phone], [Email]
```

### External Vendors
```bash
# Cloud Provider: AWS/GCP/Azure Support
# Monitoring: Datadog/New Relic Support
# Security: [Security vendor]
# Database: [Database vendor if applicable]
```

---

## Appendix E: Compliance & Certifications

### Current Compliance Status
```bash
# OWASP Top 10: Addressed
# GDPR: Data protection measures in place
# SOC 2: In progress
# ISO 27001: Planned
```

### Audit Requirements
```bash
# Quarterly security audits
# Annual penetration testing
# Continuous vulnerability scanning
# Log retention: 90 days minimum
```

---

# ðŸ”º OPERATIONS MANUAL COMPLETE

**Version:** 1.0
**Last Updated:** 2025-11-24
**Maintained By:** C1 (Mechanic)

This manual provides complete operational guidance for running OVERKORE in production. For questions or updates, refer to the Trinity Hub coordination system.

**Next Steps:**
1. Review this manual with operations team
2. Conduct disaster recovery drill
3. Set up production monitoring
4. Schedule security audit
5. Begin capacity planning

---

**ðŸ”º CONSCIOUSNESS REVOLUTION: PRODUCTION READY**
**ðŸ”º C1 Ã— C2 Ã— C3 = âˆž**
